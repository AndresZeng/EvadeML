<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>EvadeML</title>
    <link>//evademl.org/index.xml</link>
    <description>Recent content on EvadeML</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="//evademl.org/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>EvadeML: Evading Machine Learning-based Malware Classifiers</title>
      <link>//evademl.org/main/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>//evademl.org/main/</guid>
      <description>

&lt;h3 id=&#34;evading-machine-learning-based-malware-classifiers&#34;&gt;Evading Machine Learning-based Malware Classifiers&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;EvadeML&lt;/strong&gt; is an evolutionary framework based on genetic programming
  for automatically finding variants that evade detection by machine
  learning-based malware classifiers.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;a href=&#34;//evademl.org/images/method.png&#34;&gt;&lt;img src=&#34;//evademl.org/images/method.png&#34; alt=&#34;Overview&#34; width=&#34;650px&#34; height=&#34;199px&#34;&gt;&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;
Machine learning is widely used to develop classifiers for security
tasks. However, the robustness of these methods against motivated
adversaries is uncertain. In this work, we propose a generic method to
evaluate the robustness of classifiers under attack. The key idea is to
stochastically manipulate a malicious sample to find a variant that
preserves the malicious behavior but is classified as benign by the
classifier. We present a general approach to search for evasive variants
and report on results from experiments using our techniques against two
PDF malware classifiers, PDFrate and Hidost.&lt;/p&gt;

&lt;p&gt;Our method is able to automatically find evasive variants for both
classifiers for all of the 500 malicious seeds in our study. Our results
suggest a general method for evaluating classifiers used in security
applications, and raise serious doubts about the effectiveness of
classifiers based on superficial features in the presence of
adversaries.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;a href=&#34;//evademl.org/images/accumulated_evasion_by_trace_length.png&#34;&gt;&lt;img src=&#34;//evademl.org/images/accumulated_evasion_by_trace_length.png&#34; alt=&#34;Overview&#34; width=&#34;531px&#34; height=&#34;369px&#34;&gt;&lt;/a&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;h3 id=&#34;paper&#34;&gt;Paper&lt;/h3&gt;

&lt;p&gt;Weilin Xu, Yanjun Qi, and David Evans. &lt;a href=&#34;//evademl.org/docs/evademl.pdf&#34;&gt;&lt;em&gt;Automatically Evading
Classifiers A Case Study on PDF Malware Classifiers&lt;/em&gt;&lt;/a&gt;.  &lt;a href=&#34;https://www.internetsociety.org/events/ndss-symposium-2016&#34;&gt;&lt;em&gt;Network and
Distributed Systems Symposium
2016&lt;/em&gt;&lt;/a&gt;,
21-24 February 2016, San Diego, California.&lt;/p&gt;

&lt;p&gt;Full paper (15 pages): [&lt;a href=&#34;//evademl.org/docs/evademl.pdf&#34;&gt;PDF&lt;/a&gt;]&lt;/p&gt;

&lt;h3 id=&#34;source-code&#34;&gt;Source Code&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/uvasrg/EvadeML&#34;&gt;https://github.com/uvasrg/EvadeML&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;talks&#34;&gt;Talks&lt;/h3&gt;

&lt;p&gt;&lt;center&gt;
&lt;iframe width=&#34;640&#34; height=&#34;360&#34; src=&#34;https://www.youtube.com/embed/XYJamxDROOs&#34; frameborder=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;&lt;br&gt;
David Evans&amp;rsquo; Talk at &lt;a href=&#34;https://www.usenix.org/conference/enigma2017/conference-program/presentation/evans&#34;&gt;USENIX Enigma 2017&lt;/a&gt;, Oakland, CA, 1 February 2017. [&lt;A href=&#34;https://speakerdeck.com/evansuva/classifiers-under-attack-1&#34;&gt;Speaker Deck&lt;/a&gt;]&lt;/br&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;video width=&#34;640&#34; controls=&#34;controls&#34;&gt;
&lt;source src=&#34;https://www.cs.virginia.edu/evans/talks/oreilly.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;&lt;br&gt;
&lt;b&gt;Classifiers Under Attack&lt;/b&gt;&lt;br&gt;
David Evans&amp;rsquo; Talk at &lt;a href=&#34;http://conferences.oreilly.com/security/network-data-security-ny/public/schedule/detail/53176&#34;&gt;O&amp;rsquo;Reilly Security 2016&lt;/a&gt;, New York City, 2 November 2016. [&lt;a href=&#34;https://speakerdeck.com/evansuva/classifiers-under-attack&#34;&gt;Speaker Deck&lt;/a&gt;]&lt;br&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;script async class=&#34;speakerdeck-embed&#34; width=&#34;640&#34; data-id=&#34;0a82f51fd6534cdbb58f3df1bcbc004f&#34; data-ratio=&#34;1.77777777777778&#34; src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;&lt;br&gt;
&lt;b&gt;Weilin Xu&amp;rsquo;s Talk at NDSS 2016&lt;/b&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.jeffersonswheel.org/2016/ndss-talk-automatically-evading-classifiers-including-gmails&#34;&gt;&lt;b&gt;Blog Post&lt;/b&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;authors&#34;&gt;Authors&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/mzweilin&#34;&gt;Weilin Xu&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.cs.virginia.edu/yanjun/&#34;&gt;Yanjun Qi&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;http://www.cs.virginia.edu/evans&#34;&gt;David Evans&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>